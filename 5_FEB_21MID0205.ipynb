{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING USING NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('belford', ['B', 'EH1', 'L', 'F', 'ER0', 'D'])\n",
      "('belfry', ['B', 'EH1', 'L', 'F', 'R', 'IY0'])\n",
      "('belgacom', ['B', 'EH1', 'L', 'G', 'AH0', 'K', 'AA0', 'M'])\n",
      "('belgacom', ['B', 'EH1', 'L', 'JH', 'AH0', 'K', 'AA0', 'M'])\n",
      "('belgard', ['B', 'EH0', 'L', 'G', 'AA1', 'R', 'D'])\n",
      "('belgarde', ['B', 'EH0', 'L', 'G', 'AA1', 'R', 'D', 'IY0'])\n",
      "('belge', ['B', 'EH1', 'L', 'JH', 'IY0'])\n",
      "('belger', ['B', 'EH1', 'L', 'G', 'ER0'])\n",
      "('belgian', ['B', 'EH1', 'L', 'JH', 'AH0', 'N'])\n",
      "('belgians', ['B', 'EH1', 'L', 'JH', 'AH0', 'N', 'Z'])\n",
      "('belgique', ['B', 'EH0', 'L', 'ZH', 'IY1', 'K'])\n",
      "(\"belgique's\", ['B', 'EH0', 'L', 'JH', 'IY1', 'K', 'S'])\n",
      "('belgium', ['B', 'EH1', 'L', 'JH', 'AH0', 'M'])\n",
      "(\"belgium's\", ['B', 'EH1', 'L', 'JH', 'AH0', 'M', 'Z'])\n",
      "('belgo', ['B', 'EH1', 'L', 'G', 'OW2'])\n",
      "('belgrade', ['B', 'EH1', 'L', 'G', 'R', 'EY0', 'D'])\n",
      "('belgrade', ['B', 'EH1', 'L', 'G', 'R', 'AA2', 'D'])\n",
      "(\"belgrade's\", ['B', 'EH1', 'L', 'G', 'R', 'EY0', 'D', 'Z'])\n",
      "(\"belgrade's\", ['B', 'EH1', 'L', 'G', 'R', 'AA2', 'D', 'Z'])\n",
      "('belgrave', ['B', 'EH1', 'L', 'G', 'R', 'EY2', 'V'])\n",
      "('beli', ['B', 'EH1', 'L', 'IY0'])\n",
      "('belich', ['B', 'EH1', 'L', 'IH0', 'K'])\n",
      "('belie', ['B', 'IH0', 'L', 'AY1'])\n",
      "('belied', ['B', 'IH0', 'L', 'AY1', 'D'])\n",
      "('belief', ['B', 'IH0', 'L', 'IY1', 'F'])\n"
     ]
    }
   ],
   "source": [
    "#importing the library\n",
    "import nltk\n",
    "entries = nltk.corpus.cmudict.entries()\n",
    "len(entries)\n",
    "for entry in entries[10000:10025]:\n",
    "    print(entry)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('school.n.01'),\n",
       " Synset('school.n.02'),\n",
       " Synset('school.n.03'),\n",
       " Synset('school.n.04'),\n",
       " Synset('school.n.05'),\n",
       " Synset('school.n.06'),\n",
       " Synset('school.n.07'),\n",
       " Synset('school.v.01'),\n",
       " Synset('educate.v.03'),\n",
       " Synset('school.v.03')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('school')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('school.n.01') : an educational institution\n",
      "Synset('school.n.02') : a building where young people receive education\n",
      "Synset('school.n.03') : the process of being formally educated at a school\n",
      "Synset('school.n.04') : a body of creative artists or writers or thinkers linked by a similar style or by similar teachers\n",
      "Synset('school.n.05') : the period of instruction in a school; the time period when school is in session\n",
      "Synset('school.n.06') : an educational institution's faculty and students\n",
      "Synset('school.n.07') : a large group of fish\n",
      "Synset('school.v.01') : educate in or as if in a school\n",
      "Synset('educate.v.03') : teach or refine to be discriminative in taste or judgment\n",
      "Synset('school.v.03') : swim in or form a large group of fish\n"
     ]
    }
   ],
   "source": [
    "#Prints the definition of each synset.\n",
    "for synset in wn.synsets('school'):\n",
    "    print(synset, \":\", synset.definition())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The algorithm does not always return real words, but it helps in reducing words to their root for NLP tasks.\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmerporter = PorterStemmer()\n",
    "stemmerporter.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This imports the LancasterStemmer, which is used to stem words to their root/base form.\n",
    "from nltk.stem import LancasterStemmer\n",
    "stemmerporter = LancasterStemmer()\n",
    "stemmerporter.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manag'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unlike Porter and Lancaster, which work only for English, SnowballStemmer supports French, Spanish, German, and more.\n",
    "from nltk.stem import SnowballStemmer\n",
    "SnowballStemmer.languages\n",
    "frenchstemmer = SnowballStemmer('french')\n",
    "frenchstemmer.stem('manages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "character:0\n",
      "engine:1\n",
      "good:2\n",
      "is:3\n",
      "optical:4\n",
      "recognition:5\n",
      "significant:6\n",
      "tessaract:7\n",
      "[[0 0 1 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#vectorization technique that converts text into a bag-of-words (BoW) representation.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(binary = True)\n",
    "corpus = [\"Tessaract is good optical character recognition engine\", \"optical character recognition is significant\"]\n",
    "vect.fit(corpus)\n",
    "\n",
    "vocab = vect.vocabulary_\n",
    "for key in sorted(vocab.keys()):\n",
    "    print(\"{}:{}\".format(key, vocab[key]))\n",
    "print(vect.transform([\"This is a good optical illusion. It is a good one.\"]).toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75592895 0.67082039]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(vect.transform([\"Google Cloud Vision is a character recognition engine\"]),\n",
    "                               vect.transform(corpus))\n",
    "print(similarity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vect.transform([\"Google cloud Vision is a character recognition engine\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
